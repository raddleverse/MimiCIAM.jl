{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup for Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gams = \"../data/validation_data/gams\"\n",
    "validation_julia = \"../data/validation_data/julia\"\n",
    "segnames = pd.read_csv(\"../data/subsets/random10.csv\", header = None)\n",
    "\n",
    "segnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Prep a Subset of the GAMS Data (Run Once)\n",
    "\n",
    "Note here we will use the RCP8.5 baseline results from Diaz 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need all the gams data locally\n",
    "dir_gams = \"/Users/lisarennels/JuliaProjects/CIAMPaper/local-data/gams-outputs/gams-results\"\n",
    "\n",
    "# get file names\n",
    "files_rcp85 = [\"rcp85p50ref\"+str(k)+\".csv\" for k in range(1,11)]\n",
    "\n",
    "# read all files and place in a list of Pandas dataframes\n",
    "dfG_all = []\n",
    "for file in files_rcp85:\n",
    "    dfG_all.append(pd.read_csv(dir_gams+\"/rcp85/\"+file))\n",
    "\n",
    "# concatenate all into a master file. don't worry about the times being out of order; the \n",
    "# calculations will specify the year and type of damages to be summed up later\n",
    "dfG = pd.concat(dfG_all)\n",
    "\n",
    "dfG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for just the subset of segments we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSubset = dfG.loc[dfG[\"segments\"].isin(segnames[0])]\n",
    "dfSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSubset.to_csv(validation_gams + \"rcp85p50ref_random10.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfSubset, dfG, dfG_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Pull Diaz Data\n",
    "\n",
    "Note here we will use the RCP8.5 baseline results from Diaz 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG = pd.read_csv(validation_gams + \"rcp85p50ref_random10.csv\")\n",
    "dfG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the segment names with apostrophes in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in dfG.segments.unique():\n",
    "    if '\\'' in seg:\n",
    "        new_name = seg.replace('\\'', '') \n",
    "        dfG.loc[(dfG.segments==seg), \"segments\"] = new_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather up Diaz 2016 results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoAdaptCost, OptimalCost, FloodNoAdapt, WetlandNoAdapt, RelocateNoAdapt, StormCapitalNoAdapt, StormPopNoAdapt, WetlandRetreat, WetlandProtect = [], [], [], [], [], [], [], [], []\n",
    "Construct10, ProtectCost10, StormPopProtect10, StormCapitalProtect10 = [], [], [], []\n",
    "Construct10000, ProtectCost10000, StormPopProtect10000, StormCapitalProtect10000 = [], [], [], []\n",
    "RetreatCost10, StormPopRetreat10, StormCapitalRetreat10, RelocateRetreat10 = [], [], [], []\n",
    "RetreatCost10000, StormPopRetreat10000, StormCapitalRetreat10000, RelocateRetreat10000 = [], [], [], []\n",
    "for t in range(1,11):\n",
    "    NoAdaptCost.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"NoAdaptCost\"), \"value\"].sum())\n",
    "    OptimalCost.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"OptimalFixedCost\"), \"value\"].sum())\n",
    "    FloodNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"FloodNoAdapt\"), \"value\"].sum())\n",
    "    WetlandNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandNoAdapt\"), \"value\"].sum())\n",
    "    RelocateNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"RelocateNoAdapt\"), \"value\"].sum())\n",
    "    StormCapitalNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"StormCapitalNoAdapt\"), \"value\"].sum())\n",
    "    StormPopNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"StormPopNoAdapt\"), \"value\"].sum())\n",
    "    WetlandRetreat.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandRetreat\"), \"value\"].sum())\n",
    "    WetlandProtect.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandProtect\"), \"value\"].sum())\n",
    "    Construct10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"ConstructOptimalFixed\"), \"value\"].sum())\n",
    "    ProtectCost10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"ProtectCost\"), \"value\"].sum())\n",
    "    StormPopProtect10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormPopProtect\"), \"value\"].sum())\n",
    "    StormCapitalProtect10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormCapitalProtect\"), \"value\"].sum())\n",
    "    RetreatCost10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"RetreatCost\"), \"value\"].sum())\n",
    "    StormPopRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormPopRetreat\"), \"value\"].sum())\n",
    "    StormCapitalRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormCapitalRetreat\"), \"value\"].sum())\n",
    "    RelocateRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"RelocateRetreat\"), \"value\"].sum())\n",
    "    Construct10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"ConstructOptimalFixed\"), \"value\"].sum())\n",
    "    ProtectCost10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"ProtectCost\"), \"value\"].sum())\n",
    "    StormPopProtect10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormPopProtect\"), \"value\"].sum())\n",
    "    StormCapitalProtect10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormCapitalProtect\"), \"value\"].sum())\n",
    "    RetreatCost10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"RetreatCost\"), \"value\"].sum())\n",
    "    StormPopRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormPopRetreat\"), \"value\"].sum())\n",
    "    StormCapitalRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormCapitalRetreat\"), \"value\"].sum())\n",
    "    RelocateRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"RelocateRetreat\"), \"value\"].sum())\n",
    "\n",
    "dfDiaz = pd.DataFrame()\n",
    "dfDiaz[\"time\"] = list(range(2010,2110,10))\n",
    "dfDiaz[\"NoAdapt\"] = NoAdaptCost\n",
    "dfDiaz[\"Optimal\"] = OptimalCost\n",
    "dfDiaz[\"FloodNoAdapt\"] = FloodNoAdapt\n",
    "dfDiaz[\"WetlandNoAdapt\"] = WetlandNoAdapt\n",
    "dfDiaz[\"RelocateNoAdapt\"] = RelocateNoAdapt\n",
    "dfDiaz[\"StormCapitalNoAdapt\"] = StormCapitalNoAdapt\n",
    "dfDiaz[\"StormPopNoAdapt\"] = StormPopNoAdapt\n",
    "dfDiaz[\"WetlandProtect\"] = WetlandProtect\n",
    "#dfDiaz[\"Construct\"] = Construct\n",
    "dfDiaz[\"WetlandRetreat\"] = WetlandRetreat\n",
    "dfDiaz[\"ProtectCost10\"] = ProtectCost10\n",
    "dfDiaz[\"StormPopProtect10\"] = StormPopProtect10\n",
    "dfDiaz[\"StormCapitalProtect10\"] = StormCapitalProtect10\n",
    "dfDiaz[\"RetreatCost10\"] = RetreatCost10\n",
    "dfDiaz[\"StormPopRetreat10\"] = StormPopRetreat10\n",
    "dfDiaz[\"StormCapitalRetreat10\"] = StormCapitalRetreat10\n",
    "dfDiaz[\"RelocateRetreat10\"] = RelocateRetreat10\n",
    "dfDiaz[\"ProtectCost10000\"] = ProtectCost10000\n",
    "dfDiaz[\"StormPopProtect10000\"] = StormPopProtect10000\n",
    "dfDiaz[\"StormCapitalProtect10000\"] = StormCapitalProtect10000\n",
    "dfDiaz[\"RetreatCost10000\"] = RetreatCost10000\n",
    "dfDiaz[\"StormPopRetreat10000\"] = StormPopRetreat10000\n",
    "dfDiaz[\"StormCapitalRetreat10000\"] = StormCapitalRetreat10000\n",
    "dfDiaz[\"RelocateRetreat10000\"] = RelocateRetreat10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Julia Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC = pd.read_csv(validation_julia + \"/ctrl+noConstrFix_global_85p50ssp0fixed.csv\")\n",
    "dfN = pd.read_csv(validation_julia + \"/ctrl+noConstrFix_seg_85p50ssp0fixed.csv\")\n",
    "dfO = pd.read_csv(validation_julia + \"/ctrl+noConstrFix_seg_85p50ssp0fixed_optimal.csv\") # optimal actions for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC1 = dfC.copy() # copies so that the new, shorter-foresight model version can be compared to old perfect foresight version\n",
    "dfN1 = dfN.copy()\n",
    "dfO1 = dfO.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPV foresight correction\n",
    "\n",
    "This correction accounts for the fact that the new version of CIAM considers NPV over the current adaptation period (40-50 years generally), whereas the previous GAMS version assumes NPV is known across the entire model time horizon (2000-2100, for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discount factor \n",
    "\n",
    "Matches output from a run model in Julia `m[:slrcost, :discountfactor]`\n",
    "\n",
    "`v.discountfactor[TimestepIndex(i)] = 1/(1 + p.discountrate)^(p.tstep * (i-1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drate = 0.04\n",
    "tstep = 10\n",
    "discountfactor = 1/(1+drate)**(tstep*np.arange(0,20,1))\n",
    "print(discountfactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_G, segments_N = {}, {}\n",
    "for t in range(1,21):\n",
    "    segments_G[t] = list(dfG.loc[(dfG.time==t), \"segments\"].unique())\n",
    "    segments_N[t] = list(dfN.loc[(dfN.time==t), \"segments\"].unique())\n",
    "segments_G[\"all\"] = list(dfG.segments.unique())\n",
    "segments_N[\"all\"] = list(dfN.segments.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do the first time step separately. it is special because in the \"fixed\" mode a la original (GAMS) CIAM, this is where the adaptation strategy is determined. This strategy (including level) will be followed throughout the time horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol= 0.0001\n",
    "levs = {\"RetreatCost\" : [1,10,100,1000,10000], \"ProtectCost\" : [10,100,1000,10000], \"NoAdaptCost\" : [0]}\n",
    "options = []\n",
    "for var in [\"RetreatCost\",\"ProtectCost\"]:\n",
    "    for lev in levs[var]:\n",
    "            options.append(var+str(lev))\n",
    "options.append(\"NoAdaptCost0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find which segments have a mismatch; otherwise, this fix won't do anything since there's no change to the segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_G = {}\n",
    "dfGsub = dfG.loc[(dfG.time==1) & (dfG.variable.isin([\"OptimalFixedCost\",\"NoAdaptCost\",\"ProtectCost\",\"RetreatCost\"]))]\n",
    "for seg in dfGsub.loc[(dfGsub.time==1)&(dfGsub.variable==\"OptimalFixedCost\"), \"segments\"].unique():\n",
    "    cost = float(dfGsub.loc[(dfGsub.time==1) & (dfGsub.segments==seg) & (dfGsub.variable==\"OptimalFixedCost\"), \"value\"])\n",
    "    level_action = dfGsub.loc[(dfGsub.time==1) & (dfGsub.segments==seg) & \n",
    "                              (dfGsub.value==cost) & (dfGsub.variable!=\"OptimalFixedCost\"),[\"level\",\"variable\"]]\n",
    "    if level_action[\"variable\"].iloc[0]==\"NoAdaptCost\":\n",
    "        actions_G[seg] = level_action[\"variable\"].iloc[0]+\"0\"\n",
    "    else:\n",
    "        actions_G[seg] = level_action[\"variable\"].iloc[0]+str(int(level_action[\"level\"].iloc[0]))\n",
    "        \n",
    "actions_N = {}\n",
    "dfNsub = dfN.loc[(dfN.time==1) & (dfN.variable.isin([\"OptimalCost\",\"NoAdaptCost\",\"ProtectCost\",\"RetreatCost\"]))]\n",
    "for seg in dfNsub.loc[(dfNsub.time==1)&(dfNsub.variable==\"OptimalCost\"), \"segments\"].unique():\n",
    "    cost = float(dfNsub.loc[(dfNsub.time==1) & (dfNsub.segments==seg) & (dfNsub.variable==\"OptimalCost\"), \"value\"])\n",
    "    level_action = dfNsub.loc[(dfNsub.time==1) & (dfNsub.segments==seg) & \n",
    "                              (dfNsub.value==cost) & (dfNsub.variable!=\"OptimalCost\"),[\"level\",\"variable\"]]\n",
    "    if level_action[\"variable\"].iloc[0]==\"NoAdaptCost\":\n",
    "        actions_N[seg] = level_action[\"variable\"].iloc[0]+\"0\"\n",
    "    else:\n",
    "        actions_N[seg] = level_action[\"variable\"].iloc[0]+str(int(level_action[\"level\"].iloc[0]))\n",
    "        \n",
    "mismatches = {}\n",
    "for seg in actions_G.keys():\n",
    "    if actions_G[seg]!=actions_N[seg]:\n",
    "        mismatches[seg] = (actions_G[seg],actions_N[seg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the NPV using the full time horizon for decision-making (entire simulation period), instead of the new version's shorter time horizon (40-50 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbeg = time.time()\n",
    "\n",
    "new_costs, new_NPV = [0]*len(mismatches), [0]*len(mismatches)\n",
    "new_choices = [0]*len(mismatches)\n",
    "old_costs = [0]*len(mismatches)\n",
    "\n",
    "# dict keys don't have fixed order, so save as a list\n",
    "mismatch_segments = list(mismatches.keys())\n",
    "\n",
    "# subset to only segments we need\n",
    "dfNsub = dfN.loc[(dfN.segments.isin(mismatch_segments))]\n",
    "dfOsub = dfO.loc[(dfO.segments.isin(mismatch_segments))]\n",
    "dfGsub = dfG.loc[(dfG.segments.isin(mismatch_segments))]\n",
    "\n",
    "for seg in mismatch_segments:\n",
    "    s = mismatch_segments.index(seg)\n",
    "\n",
    "    t=1 # needs to be reset each segment\n",
    "    option_costs = []\n",
    "    for var in [\"RetreatCost\",\"ProtectCost\",\"NoAdaptCost\"]:\n",
    "        for lev in levs[var]:\n",
    "            if var != \"NoAdaptCost\":\n",
    "                NPV = dfNsub.loc[(dfNsub.variable==var) & (dfNsub.segments==seg) & \n",
    "                                 (dfNsub.level==lev), \"value\"]*discountfactor\n",
    "            else:\n",
    "                NPV = dfNsub.loc[(dfNsub.variable==var) & (dfNsub.segments==seg),\"value\"]*discountfactor\n",
    "            option_costs.append(np.sum(NPV))\n",
    "    new_NPV[s] = min(option_costs)\n",
    "    new_choices[s] = options[option_costs.index(new_NPV[s])]\n",
    "    # get the new optimal costs in this time step\n",
    "    var = new_choices[s][:7]+\"Cost\"  # RetreatCost, ProtectCost, NoAdaptCost\n",
    "    lev = int(re.findall(r'\\d+', new_choices[s])[0])\n",
    "    if var != \"NoAdaptCost\":\n",
    "        new_costs[s] = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                        (dfNsub.variable==var) & (dfNsub.level==lev), \"value\"])\n",
    "    else:\n",
    "        new_costs[s] = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                        (dfNsub.variable==var), \"value\"])\n",
    "    old_costs[s] = float(dfOsub.loc[(dfOsub.segments==seg) & (dfOsub.time==t), \"OptimalCost\"])\n",
    "\n",
    "    # correct the results dataframes to match the GAMS version's perfect foresight\n",
    "    dfO.loc[(dfO.segments==seg),\"variable\"] = var  # these are assuming fixed mode\n",
    "    dfO.loc[(dfO.segments==seg),\"level\"] = lev\n",
    "    dfO.loc[(dfO.segments==seg) & (dfO.time==t),\"OptimalCost\"] = new_costs[s]\n",
    "    dfN.loc[(dfN.segments==seg) & (dfN.time==t) & (dfN.variable==\"OptimalCost\"), \"value\"] = new_costs[s]\n",
    "    dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] = dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] - \\\n",
    "                                                                      old_costs[s] + new_costs[s]\n",
    "    # In subsequent years, the choice and level stay the same. So, just need to correct things in dfO, dfN, and dfC. \n",
    "    # Retain the other versions of these dataframes from above to compare how the perfect foresight leads to an overestimation of costs.\n",
    "    for t in dfC.time.unique()[1:]:\n",
    "        if var!=\"NoAdaptCost\":\n",
    "            optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                       (dfNsub.variable==var) & (dfNsub.level==lev), \"value\"])\n",
    "        else:\n",
    "            optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                       (dfNsub.variable==var), \"value\"])\n",
    "        old_optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & (dfNsub.variable==\"OptimalCost\"), \"value\"])\n",
    "        dfN.loc[(dfN.segments==seg) & (dfN.time==t) & (dfN.variable==\"OptimalCost\"), \"value\"] = optcost\n",
    "        dfO.loc[(dfO.segments==seg) & (dfO.time==t), \"OptimalCost\"] = optcost\n",
    "        dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] += optcost - old_optcost\n",
    "        \n",
    "tend = time.time()\n",
    "print((tend-tbeg)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process DataFrames\n",
    "\n",
    "define a function to process a pair of results DataFrames (need optimal costs/actions one, the total costs one, and the subcosts one) into the form needed to make the bar chart decomposition of costs (below). Assumes `fixed=true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_costs_df(dfC, dfO, dfN, tmax=False):\n",
    "    # set up\n",
    "    ntime = len(dfO.time.unique())\n",
    "    levs = {\"RetreatCost\" : [1,10,100,1000,10000], \"ProtectCost\" : [10,100,1000,10000], \"NoAdaptCost\" : [0]}\n",
    "    \n",
    "    # figure out which segments pursue which adaptation options, and at what levels of protection\n",
    "    actions = {}\n",
    "    for choice in levs.keys():\n",
    "        for lev in levs[choice]:\n",
    "            if lev > 0:\n",
    "                actions[choice+str(lev)] = list(dfO.loc[(dfO.time==1)&(dfO.variable==choice)&(dfO.level==lev),\"segments\"])\n",
    "            else:\n",
    "                actions[choice+str(lev)] = list(dfO.loc[(dfO.time==1)&(dfO.variable==choice),\"segments\"])\n",
    "    retreat_segs, protect_segs = [], []\n",
    "    for lev in levs[\"RetreatCost\"]:\n",
    "        retreat_segs += actions[\"RetreatCost\"+str(lev)]\n",
    "    for lev in levs[\"ProtectCost\"]:\n",
    "        protect_segs += actions[\"ProtectCost\"+str(lev)]\n",
    "        \n",
    "    # tally up costs associated with each action\n",
    "    retreat_costs_N = [0]*ntime\n",
    "    protect_costs_N = [0]*ntime\n",
    "    inundation_costs_N = [0]*ntime\n",
    "    wetland_costs_N = [0]*ntime\n",
    "    flood_costs_N = [0]*ntime\n",
    "    \n",
    "    for t in range(1,ntime+1):\n",
    "        dfNsub = dfN.loc[(dfN.time==t)] # subset to speed the loop up\n",
    "        # retreat\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            retreat_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"RelocateRetreat\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        retreat_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"RelocateNoAdapt\"), \"value\"].sum()\n",
    "        # protect\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            protect_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"Construct\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        # inundation (Flood)\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            inundation_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"FloodRetreat\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        inundation_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"FloodNoAdapt\"), \"value\"].sum()\n",
    "        # wetland\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"WetlandRetreat\"), \"value\"].sum()\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"WetlandProtect\"), \"value\"].sum()\n",
    "        wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"WetlandNoAdapt\"), \"value\"].sum()\n",
    "        # flooding (Storm)\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.level==lev) & (dfNsub.variable.isin([\"StormCapitalRetreat\",\"StormPopRetreat\"])), \"value\"].sum()\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.level==lev) & (dfNsub.variable.isin([\"StormCapitalProtect\",\"StormPopProtect\"])), \"value\"].sum()\n",
    "        flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable.isin([\"StormCapitalNoAdapt\",\"StormPopNoAdapt\"])), \"value\"].sum()\n",
    "\n",
    "    if not tmax:\n",
    "        tmax = ntime\n",
    "        \n",
    "    dfNew = pd.DataFrame()\n",
    "    dfNew[\"time\"] = list(range(1,ntime+1))\n",
    "    dfNew[\"NoAdapt\"] = list(dfC.loc[(dfC.variable==\"NoAdaptCost\"), \"value\"])\n",
    "    dfNew[\"Optimal\"] = list(dfC.loc[(dfC.variable==\"OptimalCost\"), \"value\"])\n",
    "    dfNew[\"FloodNoAdapt\"] = list(dfC.loc[(dfC.variable==\"FloodNoAdapt\"), \"value\"])\n",
    "    dfNew[\"WetlandNoAdapt\"] = list(dfC.loc[(dfC.variable==\"WetlandNoAdapt\"), \"value\"])\n",
    "    dfNew[\"RelocateNoAdapt\"] = list(dfC.loc[(dfC.variable==\"RelocateNoAdapt\"), \"value\"])\n",
    "    dfNew[\"StormCapitalNoAdapt\"] = list(dfC.loc[(dfC.variable==\"StormCapitalNoAdapt\"), \"value\"])\n",
    "    dfNew[\"StormPopNoAdapt\"] = list(dfC.loc[(dfC.variable==\"StormPopNoAdapt\"), \"value\"])\n",
    "    dfNew[\"RetreatOptimal\"] = retreat_costs_N\n",
    "    dfNew[\"ProtectOptimal\"] = protect_costs_N\n",
    "    dfNew[\"InundationOptimal\"] = inundation_costs_N\n",
    "    dfNew[\"WetlandOptimal\"] = wetland_costs_N\n",
    "    dfNew[\"FloodOptimal\"] = flood_costs_N\n",
    "    dfNew = dfNew.loc[(dfNew.time <= tmax)]\n",
    "    \n",
    "    return dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline result - matching to GAMS CIAM, both with perfect foresight\n",
    "dfNew0 = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)\n",
    "dfNew0[\"year\"] = dfNew0[\"time\"]*10 + 2000\n",
    "\n",
    "# limited foresight result - only difference relative to GAMS CIAM is limited foresigh1\n",
    "dfNew1 = process_costs_df(dfC=dfC1, dfO=dfO1, dfN=dfN1, tmax=10)\n",
    "dfNew1[\"year\"] = dfNew1[\"time\"]*10 + 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compare the old results (Diaz 2016) to the new ones (this work), with the baseline model configuration. The baseline configuration should match the forcings/inputs for the Diaz 2016 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(dfD, dfN, var, lev=False, times=list(range(1,11)), verbose=True):\n",
    "    varD = var\n",
    "    names = {\"OptimalCost\" : \"OptimalFixedCost\"}#, \"Construct\" : \"ConstructOptimalFixed\"}\n",
    "    if var in names.keys():\n",
    "        varD = names[var]\n",
    "    if lev:\n",
    "        D = [dfD.loc[(dfD.variable==varD) & (dfD.level==lev) & (dfD.time==t), \"value\"].sum() for t in times]\n",
    "        N = list(dfN.loc[(dfN.variable==var) & (dfN.level==lev) & (dfN.time>=times[0]) & (dfN.time<=np.max(times)), \"value\"])\n",
    "    else:\n",
    "        D = [dfD.loc[(dfD.variable==varD) & (dfD.time==t), \"value\"].sum() for t in times]\n",
    "        N = list(dfN.loc[(dfN.variable==var) & (dfN.time>=times[0]) & (dfN.time<=np.max(times)), \"value\"])\n",
    "    if verbose:\n",
    "        print(\"time | Diaz | New\")\n",
    "        for t in range(len(times)):\n",
    "            print(times[t], np.round(D[t],3), np.round(N[t],3))\n",
    "    return [N[t]-D[t] for t in range(len(times))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking NoAdaptCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"NoAdaptCost\", lev=False, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking OptimalCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"OptimalCost\", lev=False, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check RetreatCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"RetreatCost\", lev=10, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ProtectCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"ProtectCost\", lev=10, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Construct costs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"Construct\", lev=100, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: total no-adaptation and optimal costs over time - just matching old version (GAMS, Diaz 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 1.8\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
    "\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.NoAdapt, width=3, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[0].bar(x=dfNew0.year+sep, height=dfNew0.NoAdapt, width=3, color=\"darkorange\", label=\"This work\")\n",
    "ax[0].grid(); ax[0].set_axisbelow(True)\n",
    "\n",
    "yticks = [0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2]; ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.Optimal, width=3, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[1].bar(x=dfNew0.year+sep, height=dfNew0.Optimal, width=3, color=\"darkorange\", label=\"This work\")\n",
    "ax[1].grid(); ax[1].set_axisbelow(True)\n",
    "\n",
    "yticks = [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14]; ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12);\n",
    "\n",
    "fig.savefig(\"baseline_comparison_rcp85.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: total no-adaptation and optimal costs over time - version of figure with perfect foresight (matching GAMS version) and limited foresight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### total costs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 2.5\n",
    "wid = 2.2\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
    "\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.NoAdapt, width=wid, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.NoAdapt, width=wid, color=\"darkorange\", label=\"This work, perfect foresight\")\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.NoAdapt, width=wid, color=\"firebrick\", label=\"This work, limited foresight\")\n",
    "ax[0].grid(); ax[0].set_axisbelow(True); ax[0].set_xlim([2005,2105])\n",
    "\n",
    "yticks = [0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2]; ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.Optimal, width=wid, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.Optimal, width=wid, color=\"darkorange\", label=\"This work\")\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.Optimal, width=wid, color=\"firebrick\", label=\"This work, limited foresight\")\n",
    "ax[1].grid(); ax[1].set_axisbelow(True); ax[0].set_xlim([2005,2105])\n",
    "\n",
    "yticks = [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2]; ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12);\n",
    "\n",
    "fig.savefig(\"baseline_comparison_rcp85.pdf\", bbox_inches='tight');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
